# config_mnist.yaml

# Model hyperparameters
model:
  use_performer: True
  image_size: 28
  patch_size: 7
  num_classes: 10
  model_depth: 8
  model_dim: 256
  heads: 4
  dim_head: 64
  dropout: 0.2
  kernel_fn: "ReLU"
  proj_type: "default"  # TODO: change this! ['disabled', 'default', 'learnable']
  redraw_interval: 500
  random_features: 64
  feedforward_dim_multiplier: 2

# Training hyperparameters
train:
  batch_size: 64
  test_batch_size: 1000
  epochs: 11
  lr: 1.0
  gamma: 0.7
  optimizer: "Adadelta"  
  weight_decay: 0.01
  scheduler: "CosineAnnealingLR"  
  T_max: 10
  save_model: True

# Dataset settings
dataset:
  name: "MNIST"
  transform: 
    - type: "ToTensor"
    - type: "Normalize"
      mean: [0.1307]
      std: [0.3081]

# Wandb configuration
wandb:
  project: "vit-performer-mnist"
  use_wandb: true
  log_interval: 10
  dry_run: false

# Device settings
device:
  no_cuda: false
  no_mps: false
  seed: 1







 

